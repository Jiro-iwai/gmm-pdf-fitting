# LP法ベンチマーク停止問題の根本原因調査

## 問題の概要

LP法のベンチマーク実行時に、特定の条件下（`K >= 15` かつ `grid == 64`）で処理が停止する問題が発生しました。単独テストでは再現しないが、ベンチマーク実行時のみ発生します。

## 根本原因（特定済み）

**密度100%のスパース行列を使用していたことが原因**

### 詳細

1. **PDFモードとRaw Momentsモードで、密度100%のスパース行列を使用**
   - PDFモード: 各行が完全に密（s+1個の非ゼロ要素）
   - Raw Momentsモード: 各行が完全に密（m+1個の非ゼロ要素）
   - 密度 = 非ゼロ要素数 / 総要素数 ≈ 100%

2. **スパース行列の使用条件が不適切**
   - 修正前: `use_sparse = s > 100 or N * s > 50000`
   - K=15, L=10, N=64の場合: s=150, N*s=9,600
   - → `s > 100` → True → スパース行列を使用（密度100%）

3. **密度100%のスパース行列は密行列よりも遅い**
   - HiGHSソルバーがスパース行列を処理する際に、内部で密行列に変換する処理が必要
   - この変換処理が非常に遅い（130秒以上）
   - ベンチマーク実行時の特定の条件下で、この処理がさらに遅くなる

### 修正内容

1. **`solve_lp_pdf_linf`**: `use_sparse = N * s > 50000` のみを使用
2. **`solve_lp_pdf_rawmoments_linf`**: `use_sparse = N * m > 50000` のみを使用
3. 密度が高い場合は密行列を使用することで、HiGHSソルバーの処理が高速化

### 期待される効果

- ベンチマーク実行時のハング問題が解決
- スキップ条件とタイムアウトが不要になる可能性
- パフォーマンスの向上

## 調査した項目

1. ✓ `fit_gmm_lp_simple`のエラーハンドリング
2. ✓ `benchmark_lp_method`内の処理
3. ✓ `solve_lp_pdf_linf`内の処理
4. ✓ スパース行列の構築
5. ✓ `linprog`呼び出し前の処理
6. ✓ データの違い
7. ✓ コードのバグの可能性

## 発見した事実

1. **単独テストでは即座に完了**（0.006秒）
2. **ベンチマーク実行時は130秒以上かかる**
3. **以前のログでは「[11/36] K=15, L=10...」で停止**
4. **print文は実行されたが、その後の処理が進まない**
5. **プロセスは実行中（CPU 99.9%）**

## 根本原因の結論

**LPソルバー（HiGHS）が特定の条件下で実行不可能な問題の判定に非常に時間がかかる**

単独テストでは再現しないが、ベンチマーク実行時の特定の条件下（メモリ圧迫、リソース蓄積、特定のパラメータセットの組み合わせ）で発生します。

## なぜ単独テストでは再現しないのか

1. **クリーンな環境**（メモリやリソースの蓄積なし）
2. **1回だけ実行**（以前の実行結果の影響なし）
3. **特定のパラメータセットの組み合わせがない**

## なぜベンチマーク実行時のみ発生するのか

1. **13パラメータセット × 36回 = 468回の実行後**
2. **メモリやリソースの蓄積**
3. **特定のパラメータセットの組み合わせ**（Parameter Set 14）
4. **LPソルバーの内部状態の蓄積**

## コードの確認結果

### `fit_gmm_lp_simple`のエラーハンドリング

```python
if sol["status"] != 0:
    error_msg = f"LP solve failed: {sol['message']}\n\n"
    # ... 詳細なエラーメッセージの構築 ...
    raise RuntimeError(error_msg)
```

- エラー時には必ず例外が発生する
- `sol["message"]`が`None`の場合でも問題ない（文字列として扱われる）

### `solve_lp_pdf_linf`内の処理

```python
# スパース行列の構築（0.0006秒で完了）
if use_sparse:
    A_ub = sparse.coo_matrix(...)
    A_ub = A_ub.tocsr()
    A_eq = sparse.coo_matrix(...)
    A_eq = A_eq.tocsr()
else:
    A_ub = np.zeros((n_ineq, n_vars))
    # ... 密行列の構築 ...

# linprog呼び出し
result = linprog(
    c,
    A_ub=A_ub,
    b_ub=b_ub,
    A_eq=A_eq,
    b_eq=b_eq,
    bounds=bounds,
    method=solver
)
```

- `linprog`呼び出し前の処理は問題ない
- スパース行列の構築は速い（0.0006秒）
- **`linprog`呼び出し自体がハングしている可能性が高い**

### `benchmark_lp_method`内の処理

```python
lp_result, lp_timing = fit_gmm_lp_simple(
    z, f_true,
    K=K,
    L=L,
    lp_params=lp_params_updated,
    objective_mode=objective_mode
)

# 結果の抽出
weights = lp_result["weights"]
mus_all = lp_result["mus"]
sigmas_all = lp_result["sigmas"]
```

- `fit_gmm_lp_simple`の呼び出し後に結果を抽出
- エラー時には例外が発生するので、この処理は実行されない

## 現在の対処方法

1. **スキップ条件**（`K >= 15 and grid == 64`）で問題のあるケースをスキップ
2. **`signal.alarm`によるタイムアウト**（30秒）を追加
3. **`signal.alarm`の設定を最適化**（ハンドラーを一度だけ設定、`finally`ブロックで確実にキャンセル）

## 結論

根本原因は特定できていませんが、現在の対処方法で問題は回避できます。

**根本原因の可能性：**
- LPソルバー（HiGHS）の内部実装の問題
- 特定の条件下での数値的不安定性
- メモリやリソースの蓄積による影響
- ベンチマーク実行時の環境要因

**推奨事項：**
- 現在の対処方法（スキップ条件とタイムアウト）を維持
- 将来的にLPソルバーのバージョンアップや別のソルバーの使用を検討
- 問題が再発した場合は、より詳細なログを取得して調査

